FROM ubuntu:16.04

RUN apt-get -y update
RUN apt-get -y install curl
# to avoid [working 0%] stuck
RUN apt-get -y install apt-transport-https
RUN apt-get -y install software-properties-common
# only the main depedencies are installed
RUN apt-get -y --no-install-recommends install apt-utils

# JAVA 9 or 8 ?
RUN \
  echo oracle-java8-installer shared/accepted-oracle-license-v1-1 select true | debconf-set-selections && \
  add-apt-repository -y ppa:webupd8team/java && \
  apt-get update && \
  apt-get install -y oracle-java8-installer && \
  rm -rf /var/lib/apt/lists/* && \
  rm -rf /var/cache/oracle-jdk8-installer 

# link python3
RUN \
  ln -s /usr/bin/python3 /usr/bin/python && \
  apt-get -y install python3-pip && \
  apt-get -y install python3-tk && \
  ln -s /usr/bin/pip3 /usr/bin/pip


# install sbt
RUN \
  echo "deb https://dl.bintray.com/sbt/debian /" | tee -a /etc/apt/sources.list.d/sbt.list && \
  apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 2EE0EA64E40A89B84B2DF73499E82A75642AC823 && \
  apt-get update && \
  apt-get install -y sbt

# install maven
RUN apt-get -y install maven

ARG HADOOP_VERSION=2.7.3
# use hadoop 3.0.0 at your own risk
# http://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.0.0/hadoop-3.0.0.tar.gz
ARG HADOOP_ARCHIVE=http://archive.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz
ENV HADOOP_HOME /usr/local/hadoop-${HADOOP_VERSION}
ENV HADOOP_CONF_DIR ${HADOOP_HOME}/etc/hadoop
ENV LD_LIBRARY_PATH ${HADOOP_HOME}/lib/native

# install hadoop
RUN curl -s ${HADOOP_ARCHIVE} | tar -xzvf -C /usr/local/

# set evn

ENV JAVA_HOME /usr/lib/jvm/java-8-oracle
ENV PATH $PATH:$JAVA_HOME/bin
# RUN curl -s --insecure \
#  --header "Cookie: oraclelicense=accept-securebackup-cookie;" ${JAVA_ARCHIVE} \
#  | tar -xz -C /usr/local/ && ln -s $JAVA_HOME /usr/local/java 

# SPARK
ARG SPARK_VERSION=2.3.0
# ARG SPARK_ARCHIVE=http://d3kbcqa49mib13.cloudfront.net/spark-${SPARK_VERSION}-bin-hadoop2.7.tgz
ARG SPARK_ARCHIVE=http://www-eu.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop2.7.tgz
ENV SPARK_HOME /usr/local/spark-${SPARK_VERSION}-bin-hadoop2.7
ENV PYTHONPATH ${SPARK_HOME}/python/lib/py4j-0.10.6-src.zip:${SPARK_HOME}/python

ENV PATH $PATH:${SPARK_HOME}/bin
RUN curl -s ${SPARK_ARCHIVE} | tar -xz -C /usr/local/

# install R and sparkR
RUN \
  apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9 && \
  add-apt-repository 'deb [arch=amd64,i386] https://cran.rstudio.com/bin/linux/ubuntu xenial/' && \
  apt-get update && \
  apt-get install -y libssl-dev libcurl4-openssl-dev r-base && \
  cd $SPARK_HOME/R/lib/SparkR/  && R -e "devtools::install('.')"

# alternative compiling from the source code
# RUN curl -s http://www-us.apache.org/dist/spark/spark-2.3.0/spark-2.3.0.tgz | tar -xzvf -C $SPARK_HOME && \
# cd $SPARK_HOME && build/mvn -Pyarn -Phadoop-2.7 -Pnetlib-lgpl -DskipTests clean package

WORKDIR $SPARK_HOME
